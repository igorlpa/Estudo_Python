{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified .\\notMNIST_large.tar.gz\n",
      "Found and verified .\\notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
    "last_percent_reported = None\n",
    "data_root = '.' # Change me to store data elsewhere\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\notMNIST_large already present - Skipping extraction of .\\notMNIST_large.tar.gz.\n",
      "['.\\\\notMNIST_large\\\\A', '.\\\\notMNIST_large\\\\B', '.\\\\notMNIST_large\\\\C', '.\\\\notMNIST_large\\\\D', '.\\\\notMNIST_large\\\\E', '.\\\\notMNIST_large\\\\F', '.\\\\notMNIST_large\\\\G', '.\\\\notMNIST_large\\\\H', '.\\\\notMNIST_large\\\\I', '.\\\\notMNIST_large\\\\J']\n",
      ".\\notMNIST_small already present - Skipping extraction of .\\notMNIST_small.tar.gz.\n",
      "['.\\\\notMNIST_small\\\\A', '.\\\\notMNIST_small\\\\B', '.\\\\notMNIST_small\\\\C', '.\\\\notMNIST_small\\\\D', '.\\\\notMNIST_small\\\\E', '.\\\\notMNIST_small\\\\F', '.\\\\notMNIST_small\\\\G', '.\\\\notMNIST_small\\\\H', '.\\\\notMNIST_small\\\\I', '.\\\\notMNIST_small\\\\J']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAyUlEQVR4nL2SQW7CMBBFn5MBRdRqc6Reg/v0Ar0IN+AKvQZbkFhEidPPYoxjBOoCic7me/74z/yxDB5rdpokadKOdSYb/ojnixYcQ02GnJkcVReVM4uOq9FKM96yXTs4pv7r+2MG2tOnjnarHPnZWwIsvbO5KsvMhlZAm5plZnH7yzznQ3G7+HcuVFstRXk3VVtZ0XXEBNixK9pQ7g2Tc1p13BUfRD1zsfZfygdukceoLX2MMfZsNWbyqhQD5wQYQxn//Nu+6N9eAAViVYVRzPBmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename=train_folders[0] + \"\\\\\"+os.listdir(train_folders[2])[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\notMNIST_large\\A.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\B.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\C.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\D.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\E.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\F.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\G.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\H.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\I.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_large\\J.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\A.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\B.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\C.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\D.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\E.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\F.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\G.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\H.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\I.pickle already present - Skipping pickling.\n",
      ".\\notMNIST_small\\J.pickle already present - Skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  num_images = 0\n",
    "  for image in image_files:\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (imageio.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except (IOError, ValueError) as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  for folder in data_folders:\n",
    "    set_filename = folder + '.pickle'\n",
    "    dataset_names.append(set_filename)\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "      print('Pickling %s.' % set_filename)\n",
    "      dataset = load_letter(folder, min_num_images_per_class)\n",
    "      try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "      except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folders, 45000)\n",
    "test_datasets = maybe_pickle(test_folders, 1800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19981ee9ac8>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19981c48978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f = open(train_datasets[0], 'rb')\n",
    "letter_set = pickle.load(f)\n",
    "plt.imshow(letter_set[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\notMNIST_small\\A.pickle: (1872, 28, 28)\n",
      ".\\notMNIST_small\\B.pickle: (1873, 28, 28)\n",
      ".\\notMNIST_small\\C.pickle: (1873, 28, 28)\n",
      ".\\notMNIST_small\\D.pickle: (1873, 28, 28)\n",
      ".\\notMNIST_small\\E.pickle: (1873, 28, 28)\n",
      ".\\notMNIST_small\\F.pickle: (1872, 28, 28)\n",
      ".\\notMNIST_small\\G.pickle: (1872, 28, 28)\n",
      ".\\notMNIST_small\\H.pickle: (1872, 28, 28)\n",
      ".\\notMNIST_small\\I.pickle: (1872, 28, 28)\n",
      ".\\notMNIST_small\\J.pickle: (1872, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "for a in test_datasets:\n",
    "    f = open(a, 'rb')\n",
    "    letter_set = pickle.load(f)\n",
    "    print( \"{}: {}\".format(a,letter_set.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28) (200000,)\n",
      "Validation: (10000, 28, 28) (10000,)\n",
      "Testing: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):       \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132d0f46f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[90])\n",
    "print(train_labels[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 690800506\n"
     ]
    }
   ],
   "source": [
    "\n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 28, 28)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(pickle_file, 'rb')\n",
    "file = pickle.load(f)\n",
    "file['train_dataset'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# overlaps between training and test sets: 1153 execution time: 0.997814765448851\n",
      "# overlaps between training and validation sets: 953 execution time: 0.6988421149375625\n",
      "# overlaps between validation and test sets: 55 execution time: 0.06528224935466653\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def check_overlaps(images1, images2):\n",
    "    start = time.clock()\n",
    "    hash1 = set([hash(image1.tobytes()) for image1 in images1])\n",
    "    hash2 = set([hash(image2.tobytes()) for image2 in images2])\n",
    "    all_overlaps = set.intersection(hash1, hash2)\n",
    "    return all_overlaps, time.clock()-start\n",
    "\n",
    "r, execTime = check_overlaps(train_dataset, test_dataset)    \n",
    "print( \"# overlaps between training and test sets:\", len(r), \"execution time:\", execTime)\n",
    "r, execTime = check_overlaps(train_dataset, valid_dataset)   \n",
    "print (\"# overlaps between training and validation sets:\", len(r), \"execution time:\", execTime) \n",
    "r, execTime = check_overlaps(valid_dataset, test_dataset) \n",
    "print (\"# overlaps between validation and test sets:\", len(r), \"execution time:\", execTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 (200000,)\n"
     ]
    }
   ],
   "source": [
    "train_samples_size = 100\n",
    "print(train_dataset.shape[0], train_labels.shape)\n",
    "train_index = np.random.choice(train_dataset.shape[0], train_samples_size, replace=False)\n",
    "train_sub_dataset = train_dataset[train_index]\n",
    "train_sub_labels = train_labels[train_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=100)\n",
    "\n",
    "(samples, width, height) = train_sub_dataset.shape\n",
    "X = np.reshape(train_sub_dataset,(samples,width*height))\n",
    "\n",
    "clf.fit(X, train_sub_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7237\n"
     ]
    }
   ],
   "source": [
    "(samples, width, height) = test_dataset.shape\n",
    "X_test = np.reshape(test_dataset,(samples,width*height))\n",
    "\n",
    "Ypred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(test_labels, Ypred)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 = 0.6117 \n",
    "\n",
    "100 = 0.7412\n",
    "\n",
    "1000 = 8414\n",
    "\n",
    "5000 = 0.8553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
